{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inputfile = \"../dataset/3.1_X_train.csv.gz\"\n",
    "X_valid_inputfile = \"../dataset/3.1_X_valid.csv.gz\"\n",
    "y_train_inputfile = \"../dataset/3.1_y_train.csv.gz\"\n",
    "y_valid_inputfile = \"../dataset/3.1_y_valid.csv.gz\"\n",
    "X_train = pd.read_csv(X_train_inputfile)\n",
    "X_valid = pd.read_csv(X_valid_inputfile)\n",
    "y_train = pd.read_csv(y_train_inputfile).transpose().values[0]\n",
    "y_valid = pd.read_csv(y_valid_inputfile).transpose().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(50, 301),\n",
    "    'learning_rate': stats.uniform(0.001, 1),\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_search = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recall_on_deceased(y, y_pred, **kwargs):\n",
    "    y_series = pd.Series(y)\n",
    "    y_deceased = y_series[y_series == 0]\n",
    "    y_pred_deceased = pd.Series(y_pred)[y_deceased.index]\n",
    "    return recall_score(\n",
    "        y_true = y_deceased, \n",
    "        y_pred = y_pred_deceased, \n",
    "        average = 'micro'\n",
    "    )\n",
    "\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score), \n",
    "    'Recall': make_scorer(\n",
    "        lambda y, y_pred, **kwargs:\n",
    "            recall_score(\n",
    "                y_true = y, \n",
    "                y_pred = y_pred, \n",
    "                average = 'micro'\n",
    "            )\n",
    "    ), \n",
    "    'Recall_on_deceased': make_scorer(\n",
    "        lambda y, y_pred, **kwargs:\n",
    "            _recall_on_deceased(y, y_pred, **kwargs)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    ada_model, \n",
    "    param_distributions = param_dist, \n",
    "    n_iter = n_iter_search, \n",
    "    n_jobs = -1, \n",
    "    scoring = scoring, \n",
    "    refit = 'Recall_on_deceased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top = 5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['mean_test_Recall_on_deceased'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Accuracy: {0:.3f}\".format(results['mean_test_Accuracy'][candidate]))\n",
    "            print(\"Overall recall: {0:.3f}\".format(results['mean_test_Recall'][candidate]))\n",
    "            print(\"Recall on 'deceased': {0:.3f}\".format(results['mean_test_Recall_on_deceased'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search.cv_results_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = random_search.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['outcome'] = y_train\n",
    "X_train['predict_outcome'] = pred\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.drop('outcome', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[(X_train['outcome'] == 0) & (X_train['predict_outcome'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(\n",
    "    X_train[X_train['outcome'] == 0]['outcome'], \n",
    "    X_train[X_train['outcome'] == 0]['predict_outcome'], \n",
    "    average = 'micro'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
